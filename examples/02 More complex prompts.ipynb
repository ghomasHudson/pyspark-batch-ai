{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b54e4024-d14e-444f-864d-b53bdbee424a",
   "metadata": {},
   "source": [
    "# More complex prompts\n",
    "\n",
    "As well as simple plaintext prompts, we can specify the full json of openai prompts. This allows us to support more advanced features such as multiple prompts (e.g. a system and user prompt), as well as [structured outputs](https://platform.openai.com/docs/guides/structured-outputs).\n",
    "\n",
    "Let's solve a slightly more complicated problem - extracting the names, ages, and sex of patients visiting a doctor from clinical notes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ea05e9f-400c-416f-bb63-ff82fe95fbf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>date</th><th>notes</th><th>record_id</th></tr>\n",
       "<tr><td>2025-01-01</td><td>Patient John Doe,...</td><td>7384711</td></tr>\n",
       "<tr><td>2025-01-02</td><td>Mrs. Smith, a 60-...</td><td>579110</td></tr>\n",
       "<tr><td>2025-01-05</td><td>Patient is a 30-y...</td><td>8664564</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+--------------------+---------+\n",
       "|      date|               notes|record_id|\n",
       "+----------+--------------------+---------+\n",
       "|2025-01-01|Patient John Doe,...|  7384711|\n",
       "|2025-01-02|Mrs. Smith, a 60-...|   579110|\n",
       "|2025-01-05|Patient is a 30-y...|  8664564|\n",
       "+----------+--------------------+---------+"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('sparkdf').getOrCreate()\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # for table pretty printing\n",
    "\n",
    "data = [\n",
    "    {\n",
    "        \"record_id\": \"7384711\",\n",
    "        \"date\": \"2025-01-01\",\n",
    "        \"notes\": \"Patient John Doe, a 45-year-old male, presents with a history of hypertension and complains of shortness of breath\"\n",
    "    },\n",
    "    {\n",
    "        \"record_id\": \"579110\",\n",
    "        \"date\": \"2025-01-02\",\n",
    "        \"notes\": \"Mrs. Smith, a 60-year-old female, has been experiencing severe back pain for the past month. She mentions no history of recent injuries.\"\n",
    "    },\n",
    "    {\n",
    "        \"record_id\": \"8664564\",\n",
    "        \"date\": \"2025-01-05\",\n",
    "        \"notes\": \"Patient is a 30-year-old male who presents with symptoms consistent with the flu. No known chronic conditions are reported.\"\n",
    "    },\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402867f7-e647-4f75-a73a-4559eaf24898",
   "metadata": {},
   "source": [
    "Instead of a simple plaintext prompt, let's form a json which includes both a system and user prompt, as well as enforcing a json output format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e88dd160-bf3c-4493-8f9e-4ce5209ac07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>date</th><th>notes</th><th>record_id</th><th>prompt</th></tr>\n",
       "<tr><td>2025-01-01</td><td>Patient John Doe,...</td><td>7384711</td><td>        {\\n      ...</td></tr>\n",
       "<tr><td>2025-01-02</td><td>Mrs. Smith, a 60-...</td><td>579110</td><td>        {\\n      ...</td></tr>\n",
       "<tr><td>2025-01-05</td><td>Patient is a 30-y...</td><td>8664564</td><td>        {\\n      ...</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+--------------------+---------+--------------------+\n",
       "|      date|               notes|record_id|              prompt|\n",
       "+----------+--------------------+---------+--------------------+\n",
       "|2025-01-01|Patient John Doe,...|  7384711|        {\\n      ...|\n",
       "|2025-01-02|Mrs. Smith, a 60-...|   579110|        {\\n      ...|\n",
       "|2025-01-05|Patient is a 30-y...|  8664564|        {\\n      ...|\n",
       "+----------+--------------------+---------+--------------------+"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"prompt\",\n",
    "    F.concat(\n",
    "        F.lit(\"\"\"\\\n",
    "        {\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": {\n",
    "                \"model\": \"gpt-3.5-turbo-0125\",\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": \"You are an expert name, age, and sex extractor.\"\n",
    "                            }\n",
    "                        ]\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": \"Extract the patient name, age, and sex from the following clinical note. \\\\nReturn a JSON format with the keys ['name', 'age', 'sex']:\\\\n\\\\n\"\"\"),\n",
    "        F.col(\"notes\"),\n",
    "        F.lit(\"\"\" \"\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ],\n",
    "                \"temperature\": 1,\n",
    "                \"max_tokens\": 2048,\n",
    "                \"top_p\": 1,\n",
    "                \"frequency_penalty\": 0,\n",
    "                \"presence_penalty\": 0,\n",
    "                \"response_format\": { \"type\": \"json_object\" }\n",
    "            }\n",
    "        }\"\"\")\n",
    "    ),\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35048f3a-5d98-49bf-8256-fffab2b0c795",
   "metadata": {},
   "source": [
    "Now we setup the openai client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcd28e8-eb59-4fd7-b9c2-f0cc34ce7a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4913bb-7b13-4274-961c-5d5e6e972762",
   "metadata": {},
   "source": [
    "Now let's import the `spark_batch_ai` library and process the table. We specify `prompt_is_json` which tells the model to consider the prompt as json, and the `response_format` which allows spark to parse the openai output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "564057d6-6775-4f9c-b1f2-461a03695d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-10 12:42:43.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpyspark_batch_ai.core\u001b[0m:\u001b[36mprocess_dataframe\u001b[0m:\u001b[36m120\u001b[0m - \u001b[1mDetected output format: json\u001b[0m\n",
      "\u001b[32m2025-01-10 12:42:43.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpyspark_batch_ai.core\u001b[0m:\u001b[36m_submit_and_process\u001b[0m:\u001b[36m366\u001b[0m - \u001b[1mTotal number of jobs to run: 1\u001b[0m\n",
      "\u001b[32m2025-01-10 12:42:45.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpyspark_batch_ai.core\u001b[0m:\u001b[36m_submit_and_process\u001b[0m:\u001b[36m374\u001b[0m - \u001b[1mCurrently running: 1, Jobs left in queue: 0\u001b[0m\n",
      "\u001b[32m2025-01-10 12:43:45.781\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpyspark_batch_ai.core\u001b[0m:\u001b[36mmonitor_batches\u001b[0m:\u001b[36m319\u001b[0m - \u001b[1mBatch ID: batch_678115c4e6188190981d0beac0c5df0e, Status changed from validating to in_progress\u001b[0m\n",
      "\u001b[32m2025-01-10 12:44:46.046\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpyspark_batch_ai.core\u001b[0m:\u001b[36mmonitor_batches\u001b[0m:\u001b[36m319\u001b[0m - \u001b[1mBatch ID: batch_678115c4e6188190981d0beac0c5df0e, Status changed from in_progress to completed\u001b[0m\n",
      "\u001b[32m2025-01-10 12:44:46.046\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpyspark_batch_ai.core\u001b[0m:\u001b[36mmonitor_batches\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mBatch ID batch_678115c4e6188190981d0beac0c5df0e completed. Output file ID: file-4PobYeeXLaZCHbNaQAgL9Y\u001b[0m\n",
      "\u001b[32m2025-01-10 12:44:46.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpyspark_batch_ai.core\u001b[0m:\u001b[36mmonitor_batches\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mJobs left to process: 0\u001b[0m\n",
      "\u001b[32m2025-01-10 12:44:46.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpyspark_batch_ai.core\u001b[0m:\u001b[36mmonitor_batches\u001b[0m:\u001b[36m351\u001b[0m - \u001b[1mAll batch jobs have completed.\u001b[0m\n",
      "\u001b[32m2025-01-10 12:44:46.048\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpyspark_batch_ai.core\u001b[0m:\u001b[36m_submit_and_process\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mProcessing complete.\u001b[0m\n",
      "\u001b[32m2025-01-10 12:44:46.048\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpyspark_batch_ai.core\u001b[0m:\u001b[36m_submit_and_process\u001b[0m:\u001b[36m383\u001b[0m - \u001b[1mOutput file IDs: {'batch_678115c4e6188190981d0beac0c5df0e': 'file-4PobYeeXLaZCHbNaQAgL9Y'}\u001b[0m\n",
      "\u001b[32m2025-01-10 12:44:46.703\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpyspark_batch_ai.core\u001b[0m:\u001b[36mprocess_dataframe\u001b[0m:\u001b[36m168\u001b[0m - \u001b[1mProcessing complete. Time taken: 123.78 seconds\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>date</th><th>notes</th><th>record_id</th><th>response</th></tr>\n",
       "<tr><td>2025-01-01</td><td>Patient John Doe,...</td><td>7384711</td><td>{John Doe, 45, male}</td></tr>\n",
       "<tr><td>2025-01-02</td><td>Mrs. Smith, a 60-...</td><td>579110</td><td>{Mrs. Smith, 60, ...</td></tr>\n",
       "<tr><td>2025-01-05</td><td>Patient is a 30-y...</td><td>8664564</td><td>{Patient, 30, male}</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+--------------------+---------+--------------------+\n",
       "|      date|               notes|record_id|            response|\n",
       "+----------+--------------------+---------+--------------------+\n",
       "|2025-01-01|Patient John Doe,...|  7384711|{John Doe, 45, male}|\n",
       "|2025-01-02|Mrs. Smith, a 60-...|   579110|{Mrs. Smith, 60, ...|\n",
       "|2025-01-05|Patient is a 30-y...|  8664564| {Patient, 30, male}|\n",
       "+----------+--------------------+---------+--------------------+"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark_batch_ai import process_dataframe\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "df_with_result = process_dataframe(\n",
    "    df,\n",
    "    client,\n",
    "    prompt_is_json=True,\n",
    "    response_schema=T.StructType([\n",
    "            T.StructField(\"name\", T.StringType()),\n",
    "            T.StructField(\"age\", T.StringType()),\n",
    "            T.StructField(\"sex\", T.StringType())\n",
    "    ])\n",
    ").drop(\"prompt\")\n",
    "df_with_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3a814d-0343-4a03-95d4-8fabe71706a2",
   "metadata": {},
   "source": [
    "You can then access `response.name`, `response.age` etc, or split them into seperate columns with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "da2444c8-5253-48f2-9ec1-3f8cf86ffd1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>date</th><th>notes</th><th>record_id</th><th>name</th><th>age</th><th>sex</th></tr>\n",
       "<tr><td>2025-01-01</td><td>Patient John Doe,...</td><td>7384711</td><td>John Doe</td><td>45</td><td>male</td></tr>\n",
       "<tr><td>2025-01-02</td><td>Mrs. Smith, a 60-...</td><td>579110</td><td>Mrs. Smith</td><td>60</td><td>female</td></tr>\n",
       "<tr><td>2025-01-05</td><td>Patient is a 30-y...</td><td>8664564</td><td>Patient</td><td>30</td><td>male</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+--------------------+---------+----------+---+------+\n",
       "|      date|               notes|record_id|      name|age|   sex|\n",
       "+----------+--------------------+---------+----------+---+------+\n",
       "|2025-01-01|Patient John Doe,...|  7384711|  John Doe| 45|  male|\n",
       "|2025-01-02|Mrs. Smith, a 60-...|   579110|Mrs. Smith| 60|female|\n",
       "|2025-01-05|Patient is a 30-y...|  8664564|   Patient| 30|  male|\n",
       "+----------+--------------------+---------+----------+---+------+"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_result.select(\"*\", \"response.*\").drop(\"response\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
